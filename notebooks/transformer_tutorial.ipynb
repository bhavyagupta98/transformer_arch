{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Transformer Architecture Tutorial\n",
        "\n",
        "This notebook provides a comprehensive tutorial on transformer architectures, covering:\n",
        "\n",
        "1. **Attention Mechanisms** - Understanding self-attention and multi-head attention\n",
        "2. **Positional Encoding** - How transformers handle sequence order\n",
        "3. **Complete Architecture** - Building encoder-decoder and decoder-only models\n",
        "4. **Practical Examples** - Text generation and machine translation\n",
        "5. **Visualization** - Understanding what transformers learn\n",
        "\n",
        "## Table of Contents\n",
        "1. [Setup and Imports](#setup)\n",
        "2. [Attention Mechanism Deep Dive](#attention)\n",
        "3. [Positional Encoding](#positional)\n",
        "4. [Building a Transformer](#building)\n",
        "5. [Text Generation Example](#text-gen)\n",
        "6. [Machine Translation Example](#translation)\n",
        "7. [Attention Visualization](#visualization)\n",
        "8. [Advanced Topics](#advanced)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
